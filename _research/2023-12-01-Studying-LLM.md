---
title: Studying Large Language Model Generalization with Influence Functions

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/influence-image.png

# This is optional, if not provided it will not show on the page.
subtitle: arXiv 2023

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2308.03296.pdf

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Roger Grosse*
  - name: Juhan Bae*
  - name: Cem Anil*
  - name: Nelson Elhage
  - name: Alex Tamkin
  - name: Amirhossein Tajdini
  - name: Benoit Steiner
  - name: Dustin Li
  - name: Esin Durmus
  - name: Ethan Perez
  - name: Evan Hubinger
  - name: Kamilė Lukošiūtė
  - name: Karina Nguyen
  - name: Nicholas Joseph
  - name: Sam McCandlish
  - name: Jared Kaplan
  - name: Samuel R. Bowman

links:
  - name: Talk
    url: https://www.alignment-workshop.com/nola-talks/roger-grosse-studying-llm-generalization-through-influence-functions
  - name: Twitter Thread
    url: https://twitter.com/AnthropicAI/status/1688946685937090560
---

<!--Abstract-->

We discuss gaining visibility into a machine learning model in order to understand and mitigate the associated risks.
