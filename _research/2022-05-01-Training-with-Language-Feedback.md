---
title: Training Language Models with Language Feedback

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/training_language_models_image.png

# This is optional, if not provided it will not show on the page.
subtitle: ACL 2022 Workshop on Learning with Natural Language Supervision

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2204.14146.pdf

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Jérémy Scheurer
  - name: Jon Ander Campos
  - name: Jun Shern Chan
  - name: Angelica Chen
  - name: Kyunghyun Cho
  - name: Ethan Perez

# List of links
links:
  - name: FAR AI
    url: https://far.ai/publication/scheurer2022training/
  - name: Talk 
    url: https://www.youtube.com/watch?v=oEnyl9dMKCc
---

<!--Abstract-->

We found a way to learn from language feedback (not ratings), enabling us to finetune GPT3 to human-level summarization with just 100 feedback samples.
