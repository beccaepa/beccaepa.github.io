---
title: "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/self-reports-image.png

# This is optional, if not provided it will not show on the page.
subtitle: arXiv 2023

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2305.04388.pdf

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Miles Turpin
  - name: Julian Michael
  - name: Ethan Perez
  - nameL Samuel R. Bowman
---

<!--Abstract-->

We find that CoT explanations can systematically misrepresent the true reason for a model's prediction.
