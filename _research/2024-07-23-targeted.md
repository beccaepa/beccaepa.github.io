---
title: Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/targeted-image.png

# This is optional, if not provided it will not show on the page.
subtitle: arXiv 2024

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2407.15549

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Abhay Sheshadri*
  - name: Aidan Ewart*
  - name: Phillip Guo*
  - name: Aengus Lynch*
  - name: Cindy Wu*
  - name: Vivek Hebbar*
  - name: Henry Sleight
  - name: Asa Cooper Stickland
  - name: Ethan Perez
  - name: Dylan Hadfield-Menell
  - name: Stephen Casper


links:
  - name: Code
    url: https://github.com/aengusl/latent-adversarial-traininge 
  - name: Twitter Thread
    url: https://x.com/StephenLCasper/status/1815786887824502911

---

<!--Abstract-->

To help us more thoroughly remove unwanted capabilities from LLMs, we use targeted latent adversarial training (LAT) â€“ we train models under latent-space perturbations designed to make them exhibit unwanted behaviors.
