---
title: Vision-language models are zero-shot reward models for reinforcement learning

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/Screen-Shot-2023-09-26-at-12.53.48-PM-150x150.png

# This is optional, if not provided it will not show on the page.
subtitle: arXiv 2023

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2310.12921.pdf

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Juan Rocamonde
  - name: Victoriano Montesinos
  - name: Elvis Nava
  - name: Ethan Perez
  - name: David Lindner

# List of links
links:
  - name: Paper
    url: https://arxiv.org/pdf/2310.12921.pdf
---

<!--Abstract-->

Reinforcement learning (RL) requires either manually specifying a reward function, which is often infeasible, or learning a reward model from a large amount of human feedback, which is often very expensive. We study a more sample-efficient alternative: using pretrained vision-language models (VLMs) as zero-shot reward models (RMs) to specify tasks via natural language. 
