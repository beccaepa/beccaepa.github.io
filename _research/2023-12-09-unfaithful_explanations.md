---
title: "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/unfaithful-explanation.png

# This is optional, if not provided it will not show on the page.
subtitle: NeurIPS 2023

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2305.04388.pdf

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: Miles Turpin
  - name: Julian Michael
  - name: Ethan Perez
  - name: Samuel R. Bowman

links:
  - name: Blog Post
    url: https://www.alignmentforum.org/posts/6eKL9wDqeiELbKPDj/unfaithful-explanations-in-chain-of-thought-prompting
  - name: Code
    url: https://github.com/milesaturpin/cot-unfaithfulness
---

<!--Abstract-->

We find that CoT explanations can systematically misrepresent the true reason for a model's prediction.
