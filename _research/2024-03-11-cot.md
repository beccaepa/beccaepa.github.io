---
title: Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought

# Path to the image file, example /assets/images/blog/image.jpg
# You can also use an online URL as well, example https://www.google.com/image.jpg
image: /assets/images/cot-image.jpeg

# This is optional, if not provided it will not show on the page.
subtitle: arXiv 2024

# This is optional, if not provided the title will not have a link to anywhere
link: https://arxiv.org/pdf/2403.05518

# Add list of authors here.
# Name is mandatory, url is optional.
authors:
  - name: James Chua*
  - name: Edward Rees*
  - name: Hunar Batra
  - name: Samuel R. Bowman
  - name: Julian Michael
  - name: Ethan Perez
  - name: Miles Turpin

links:
  - name: Blog Post
    url: https://nyudatascience.medium.com/new-research-finds-method-to-reduce-ai-language-models-biased-reasoning-44e62ed77a9b
  - name: Code
    url: https://github.com/raybears/cot-transparency
  - name: Twitter Thread
    url: https://x.com/milesaturpin/status/1767327882978660513

---

<!--Abstract-->

We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks.
