---
layout: home
image: /assets/images/Ethan.png
---

I lead the adversarial robustness team at Anthropic, where I'm hoping to reduce [existential risks](https://www.safe.ai/statement-on-ai-risk) from AI systems. I helped to develop [Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2005.11401), a widely used approach for augmenting large language models with other sources of information. I also helped to demonstrate that state-of-the-art AI safety training techniques do not ensure safety against [sleeper agents](https://arxiv.org/abs/2401.05566). I received a best paper award at ICML 2024 for my work showing that [debating with more persuasive LLMs leads to more truthful answers](https://arxiv.org/abs/2402.06782).

I received my PhD from NYU under the supervision of Kyunghyun Cho and Douwe Kiela and funded by NSF and Open Philanthropy. Previously, I've spent time at DeepMind, Facebook AI Research, Montreal Institute for Learning Algorithms, and Google.

[Email](mailto:perez@nyu.edu) /
[Google Scholar](https://scholar.google.ca/citations?user=za0-taQAAAAJ&hl=en) /
[GitHub](https://github.com/ethanjperez) /
[Twitter](https://twitter.com/EthanJPerez) /
[CV](/assets/pdfs/CV_2024.pdf)
